{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3zbLLaSGH6Z"
      },
      "source": [
        "## Лабораторная работа \"Введение в ML\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL3v975uGH6h"
      },
      "source": [
        "В этой лабораторной вы:\n",
        "\n",
        "- познакомитесь с базовыми библиотеками для работы с табличными данными — `numpy` и `pandas`\n",
        "- поближе посмотрите на простейшие задачи машинного обучения: классификацию и регрессию\n",
        "- попробуете несколько метрик и поймёте, почему выбор метрики это важно\n",
        "- обучите несколько простых моделей\n",
        "- увидите связь между сложностью модели и переобучением\n",
        "- убедитесь, что без данных всё тлен"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad3nBqBSGH6j"
      },
      "source": [
        "Загрузка самых базовых библиотек:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z8Iht5qhGH6l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W8Eq0sTGH6n"
      },
      "source": [
        "### [NumPy](https://numpy.org/doc/stable/user/index.html)\n",
        "\n",
        "С 1995 numeric, с 2006 NumPy — «Numerical Python extensions» или просто «NumPy»\n",
        "\n",
        "Возможности библиотеки NumPy:\n",
        "* работать с многомерными массивами (таблицами)\n",
        "* быстро вычислять математические функций на многомерных массивах\n",
        "\n",
        "Ядро пакета NumPy — объект [ndarray](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html)\n",
        "\n",
        "**Важные отличия** между NumPy arrays и Python sequences:\n",
        "* NumPy array имеет фиксированную длину, которая определяется в момент его создания (в отличие от Python lists, которые могут расти динамически)\n",
        "* Элементы в NumPy array должны быть одного типа\n",
        "* Можно выполнять операции непосредственно над NumPy arrays\n",
        "\n",
        "**Скорость** NumPy достигается с помощью:\n",
        "* реализации на C\n",
        "* векторизации и броадкастинга (broadcasting). Например, произведение массивов совместимых форм.\n",
        "\n",
        "Теперь давайте разберёмся подробнее и сделаем что-нибудь приятное и полезное в `numpy`!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS3UKcU6GH6o"
      },
      "source": [
        "### Индексация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqBzoEfvGH6p"
      },
      "source": [
        "В NumPy работает привычная индексация Python, ура! Включая использование отрицательных индексов и срезов (slices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anq_nSYTGH6q"
      },
      "source": [
        "<div class=\"alert alert-info\">\n",
        "<b>Замечание 1:</b> Индексы и срезы в многомерных массивах не нужно разделять квадратными скобками,\n",
        "т.е. вместо <b>matrix[i][j]</b> нужно использовать <b>matrix[i, j]</b>. Первое тоже работает, но сначала выдаёт строку i, потом элемент j в ней.\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoHXSVIrGH6q"
      },
      "source": [
        "<div class=\"alert alert-danger\">\n",
        "<b>Замечание 2:</b> Срезы в NumPy создают view, а не копии, как в случае срезов встроенных последовательностей Python (string, tuple and list).\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YJKxBB4dGH6s",
        "outputId": "61139b1d-46db-4f7f-d5bb-96b7c3f96284"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0.],\n",
              "       [0., 0., 0.],\n",
              "       [0., 0., 0.]])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ones_matrix = np.ones((5, 5))\n",
        "ones_submatrix_view = ones_matrix[::2,::2] # creates a view, not copy\n",
        "ones_matrix[::2,::2] = np.zeros((3, 3))\n",
        "ones_submatrix_view"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpEF1rp2GH6v"
      },
      "source": [
        "### Ссылка на Яндекс.Контест\n",
        "\n",
        "Решения и ответы в задачах, расположенных ниже, загружайте в контест на автоматическую проверку:\n",
        "https://new.contest.yandex.ru/60376/start\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZpuxPhJGH6v"
      },
      "source": [
        "**1.** Реализуйте функцию, принимающую на вход два одномерных массива `first_array` и `second_array` и возвращающую матрицу, в которой первый массив соответствует первому столбцу матрицы, второй — второму.\n",
        "\n",
        "Вероятно первое, что приходит вам на ум, это конкатенация и транспонирование:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hmQk1N6rGH6w"
      },
      "outputs": [],
      "source": [
        "def construct_matrix(first_array, second_array):\n",
        "    \"\"\"\n",
        "    Construct matrix from pair of arrays\n",
        "    :param first_array: first array\n",
        "    :param second_array: second array\n",
        "    :return: constructed matrix\n",
        "    \"\"\"\n",
        "    return np.vstack([first_array, second_array]).T # <- your first right code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TeFqyCz4GH6x",
        "outputId": "ecd0b7d3-7acf-40f2-878e-057d17136e8c",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 3],\n",
              "       [2, 4]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "construct_matrix(np.array([1,2]),np.array([3,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lP-lmcA2GH6y"
      },
      "source": [
        "(в скобках заметим, что конкатенировать можно vertically, horizontally, depth wise методами vstack, hstack, dstack по трём осям (0, 1 и 2, соотвественно), либо в общем случае `np.concatenate` — поиграйтесь ниже с прекрасным примером четырёхмерной точки, чтобы точно всё для себя понять)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xguxLJ0VGH6y",
        "outputId": "2f32df14-6f5d-4800-96b5-bb8fba9c9ec0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[0]]]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "p = np.arange(1).reshape([1, 1, 1, 1])\n",
        "p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "z1JFw75eGH6y",
        "outputId": "16e3c894-2e0e-4a5a-edd4-7a974cfa43e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vstack:  (2, 1, 1, 1)\n",
            "hstack:  (1, 2, 1, 1)\n",
            "dstack:  (1, 1, 2, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"vstack: \", np.vstack((p, p)).shape)\n",
        "print(\"hstack: \", np.hstack((p, p)).shape)\n",
        "print(\"dstack: \", np.dstack((p, p)).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cvbthbDDGH6z",
        "outputId": "d89430e5-8c64-4b5f-f2b3-4343f4c659ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1, 1, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.concatenate((p, p), axis=3).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5GkuWwaGH60"
      },
      "source": [
        "Но, поскольку операция транспонирования [делает массив non-contiguous](https://numpy.org/doc/stable/user/basics.copies.html#other-operations), мы в этой задаче **запретим** ей пользоваться и порекомедуем воспользоваться, например, методом [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3ce_o75GH61"
      },
      "source": [
        "**2.** Реализуйте функцию, принимающую на вход массив целых неотрицательных чисел `nums` и возвращающую самый частый элемент массива."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XZysMovaGH61"
      },
      "outputs": [],
      "source": [
        "def most_frequent(nums):\n",
        "    \"\"\"\n",
        "    Find the most frequent value in an array\n",
        "    :param nums: array of ints\n",
        "    :return: the most frequent value\n",
        "    \"\"\"\n",
        "    pass # your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kjITZMGH62"
      },
      "source": [
        "### Переходим к работе с данными\n",
        "\n",
        "Прежде всего, загрузим данные и сделаем из них красивые pandas-таблички. Они взяты из параллели RecSys соревнования https://yandex.ru/cup/ml/. Но мы будем иметь дело не со всеми данными, а только с их частью. Данные у нас будут про заведения общественного питания (больше бюрократический терминологии!)\n",
        "\n",
        "Файлы с данными можно найти [здесь](https://disk.yandex.ru/d/YWvCNRQMb7QSQA).\n",
        "\n",
        "Задачей будет **предсказание среднего чека** (average_bill) по некоторым другим свойствам заведения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yJPF3OclGH62"
      },
      "outputs": [],
      "source": [
        "base = 'DATAS/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uzDIu6uXGH62"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(base + 'organisations.csv')\n",
        "features = pd.read_csv(base + 'features.csv')\n",
        "rubrics = pd.read_csv(base + 'rubrics.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-AwDM7bGH63"
      },
      "source": [
        "В основном мы будем работать с табличкой `data`; остальное вам может пригодиться, если вы захотите знать, какое содержание стоит за кодами признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hrvEN_3GH63"
      },
      "source": [
        "## Изучение данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI9YQMuCGH63"
      },
      "source": [
        "Посмотрите на данные. В этом вам поможет метод ``head`` pandas-таблички."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VA_0DG29GH64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 org_id city  average_bill    rating   rubrics_id  \\\n",
            "0  15903868628669802651  msk        1500.0  4.270968  30776 30774   \n",
            "1  16076540698036998306  msk         500.0  4.375000        30771   \n",
            "2   8129364761615040323  msk         500.0  4.000000        31495   \n",
            "3  15262729117594253452  msk         500.0  4.538813  30776 30770   \n",
            "4  13418544315327784420  msk         500.0  4.409091        31495   \n",
            "\n",
            "                                         features_id  \n",
            "0  3501685156 3501779478 20422 3502045016 3502045...  \n",
            "1  1509 1082283206 273469383 10462 11617 35017794...  \n",
            "2  10462 11177 11617 11629 1416 1018 11704 11867 ...  \n",
            "3  3501618484 2020795524 11629 11617 1018 11704 2...  \n",
            "4  11617 10462 11177 1416 11867 3501744275 20282 ...  \n"
          ]
        }
      ],
      "source": [
        "print(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GN9kZbURGH64"
      },
      "source": [
        "Полезно посмотреть внимательнее на то, с какими признаками нам предстоит работать.\n",
        "\n",
        "* **org_id** вам не понадобится;\n",
        "* **city** - город, в котором находится заведение (``msk`` или ``spb``);\n",
        "* **average_bill** - средний чек в заведении - он будет нашим таргетом;\n",
        "* **rating** - рейтинг заведения;\n",
        "* **rubrics_id** - тип заведения (или несколько типов). Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``rubrics``\n",
        "* **features_id** - набор неких фичей заведения. Соответствие кодов каким-то человекочитаемым типам живёт в табличке ``features``\n",
        "\n",
        "Обратите внимание, что **rubrics_id** и **features_id** - это не списки, а разделённые пробелами строки. Когда вам захочется работать с отдельными фичами из мешка фичей для данного заведения, вам придётся всё-таки превратить их в списки (здесь поможет метод `split` для строк)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0IJIWz3GH64"
      },
      "source": [
        "Чтобы быстро восстанавливать по рубрикам и фичам их нормальные названия, сделайте словари вида ``код_фичи:название_фичи``"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8KwKEKr7GH65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0               [Ресторан, Кафе]\n",
            "1              [Быстрое питание]\n",
            "2                      [Кофейня]\n",
            "3           [Ресторан, Бар, паб]\n",
            "4                      [Кофейня]\n",
            "                  ...           \n",
            "68334                     [Кафе]\n",
            "68335                 [Ресторан]\n",
            "68336                     [Кафе]\n",
            "68337    [Быстрое питание, Кафе]\n",
            "68338                 [Ресторан]\n",
            "Name: rubrics_list, Length: 68339, dtype: object\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rubric_dict = {\n",
        "    30519: 'Булочная, пекарня',\n",
        "    30770: 'Бар, паб',\n",
        "    30771: 'Быстрое питание',\n",
        "    30774: 'Кафе',\n",
        "    30775: 'Пиццерия',\n",
        "    30776: 'Ресторан',\n",
        "    30777: 'Столовая',\n",
        "    31286: 'Спортбар',\n",
        "    31350: 'Кондитерская',\n",
        "    31375: 'Суши-бар',\n",
        "    31401: 'Кальян-бар',\n",
        "    31495: 'Кофейня',\n",
        "    3108292683: 'Бар безалкогольных напитков',\n",
        "    3501514558: 'Фудкорт',\n",
        "    3501750896: 'Кофе с собой'\n",
        "}\n",
        "data[\"rubrics_list\"] = data[\"rubrics_id\"].apply(lambda x: [rubric_dict[int(r)] for r in str(x).split() if int(r) in rubric_dict])\n",
        "print(data[\"rubrics_list\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNd4PkyQGH65"
      },
      "source": [
        "Посмотрим, какими бывают типы заведений:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "8WhaPPEeGH65",
        "outputId": "aaf9cc8c-64ae-4bac-d8f8-6dd4d03033d8",
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{30519: 'Булочная, пекарня',\n",
              " 30770: 'Бар, паб',\n",
              " 30771: 'Быстрое питание',\n",
              " 30774: 'Кафе',\n",
              " 30775: 'Пиццерия',\n",
              " 30776: 'Ресторан',\n",
              " 30777: 'Столовая',\n",
              " 31286: 'Спортбар',\n",
              " 31350: 'Кондитерская',\n",
              " 31375: 'Суши-бар',\n",
              " 31401: 'Кальян-бар',\n",
              " 31495: 'Кофейня',\n",
              " 3108292683: 'Бар безалкогольных напитков',\n",
              " 3501514558: 'Фудкорт',\n",
              " 3501750896: 'Кофе с собой'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rubric_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA6Bm_8EGH66"
      },
      "source": [
        "Мы что-то поняли про признаки, которыми нам предстоит пользоваться. Теперь время посмотреть на таргет. Вооружившись функциями ``hist`` и ``scatter`` из библиотеки ``matplotlib``, а также методом ``isna`` для pandas-таблиц разберитесь, какие значения принимают таргеты, есть ли там там выбросы, пропуски или ещё какие-то проблемы.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>Среди таргетов довольно много пропусков;</li>\n",
        "      <li>Все таргеты - это числа, кратные 500;</li>\n",
        "      <li>Есть какие-то адские значения, превышающие 100 000 (видимо, выбросы);</li>\n",
        "      <li>В целом, число ресторанов с данным средним чеком быстро падает с ростом среднего чека. Для средних чеков, больших 2500, заведений уже совсем мало. Примерно у 2/3 заведений средний чек 500.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "f6bg-kmIGH66",
        "outputId": "69beeb66-b7aa-4905-bc73-59a6ab27edf3",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество пропусков в average_bill: 35561\n"
          ]
        }
      ],
      "source": [
        "\n",
        "missing_count = data[\"average_bill\"].isna().sum()\n",
        "print(f\"Количество пропусков в average_bill: {missing_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trfl5F_4GH66"
      },
      "source": [
        "**Базовая очистка данных**\n",
        "\n",
        "Раз есть треш, давайте чистить данные.\n",
        "\n",
        "С пропусками можно бороться по-разному (даже и с пропусками в таргете), но пока мы сделаем самую простую вещь: дропнем все заведения, для которых мы не знаем средний чек.\n",
        "\n",
        "Уберите из них все заведения, у которых средний чек неизвестен или превышает 2500. Пока есть опасение, что их слишком мало, чтобы мы смогли обучить на них что-нибудь.\n",
        "\n",
        "**3. Введите в Контест количество заведений, которое у вас получилось после очистки**.\n",
        "\n",
        "Дальше мы будем работать с очищенными данными."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "OxIkRsA1GH67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество заведений после очистки: 32136\n"
          ]
        }
      ],
      "source": [
        "clean_data = data.dropna(subset=[\"average_bill\"])\n",
        "\n",
        "\n",
        "clean_data = clean_data[clean_data[\"average_bill\"] <= 2500]\n",
        "\n",
        "print(f\"Количество заведений после очистки: {len(clean_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsNzGAp1GH67"
      },
      "source": [
        "**4. Посчитайте и введите в Контест разность между средними арифметическими average_bill в кафе Москвы и Санкт-Петербурга. Округлите ответ до целого.**\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Небольшая подсказка</summary>\n",
        "  Примените часто используемый метод groupby.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gLdl3zVCGH67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "city\n",
            "msk    792.887230\n",
            "spb    676.449662\n",
            "Name: average_bill, dtype: float64 116.43756751957676 116\n"
          ]
        }
      ],
      "source": [
        "city_means = clean_data.groupby(\"city\")[\"average_bill\"].mean()\n",
        "\n",
        "difference = city_means[\"msk\"] - city_means[\"spb\"]\n",
        "\n",
        "difference_rounded = round(difference)\n",
        "print(city_means, difference, difference_rounded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qncnmi8bGH7F"
      },
      "source": [
        "Давайте ещё немного поизучаем данные. Ответьте на вопросы:\n",
        "\n",
        "1. Есть ли разница между средними чеками в Москве и Санкт-Петербурге?\n",
        "2. Коррелирует ли средний чек с рейтингом?\n",
        "3. Есть ли разница в среднем чеке между ресторанами и пабами (см. соответствующие типы из ``rubrics``)?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    <ol>\n",
        "      <li>В целом, да. Вы могли бы сравнить средние (в Москве больше) или медианы (они равны, потому что уж больно много где средний чек 500). Этого, конечно, мало для того, чтобы сделать вывод. Нужно проверять какие-то статические критерии, которые изучаются в курсе по статистике. Не будем останавливаться на этом подробно. Поскольку данные совсем не нормальные, никакой t-тест не сработает; мы бы предложили использовать критерий Манна-Уитни (см. википедию и функцию mannwhitneyu из библиотеки scipy.stats).</li>\n",
        "      <li>Какая-то корреляция между ними есть но уж больно неубедительная (рекомендуем построим на одном графике boxplot рейтинга по каждому значению среднего чека для визуализации). Конечно, дна становится меньше с ростом среднего чека, но, видимо, в предсказании это особо не используешь;</li>\n",
        "      <li>Несомненно, в ресторанах средний чек выше. Это и невооружённым глазом видно, и с помощью критерия Манна-Уитни можно проверить.</li>\n",
        "    </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATY5075lGH7F"
      },
      "source": [
        "## Формулируем задачу"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znpEgJGIGH7F"
      },
      "source": [
        "Прежде, чем решать задачу, её надо сформулировать.\n",
        "\n",
        "**Вопрос первый**: это классификация или регрессия? Подумайте над этим.\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    Ответ не столь однозначен, как хотелось бы. С одной стороны, таргет принимает всего четыре значения, и потому это может быть классификацией с 4 классами. С другой стороны, таргеты - это не абстрактные \"треугольник\", \"круг\", \"квадрат\", а вещественные числа, и когда мы вместо 500 предсказываем 2500, это явно хуже, чем вместо 1500 предсказать 2000. В целом, задачу можно решать и так, и так; мы будем смотреть на метрики обеих задач.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaVuazxsGH7G"
      },
      "source": [
        "**Вопрос второй**: какие метрики мы будем использовать для оценки качества решения? Какие метрики вы предложили бы для этой задачи как для задачи классификации? А для этой задачи, как для задачи регрессии?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Начнём с классификации. Метрика accuracy не очень хороша из-за несбалансированности классов. Действительно, классификатор, который всегда говорит 500, будет иметь accuracy примерно 0.66, хотя это никак не отражает практическую ценность модели. Как мы увидим, самая большая проблема будет заключаться в том, чтобы научиться выделять заведения с большими чеками, а их меньше всего и в accuracy они вносят самый маленький вклад. Есть разные способы с этим бороться, один -- использовать sklearn.metrics.balanced_accuracy_score. Его идея, грубо говоря, в том, чтобы по каждому классу найти, какая доля объектов этого класса правильно классифицирована, а потом эти доли усреднить. Тогда у бессмысленного классификатора, который всем ставит 500, будет скор 1/5 (ведь классов 5), а чтобы получить прежние 2/3, нужно будет научиться в каждом классе правильно ставить хотя бы 2/3 меток.    \n",
        "    \n",
        "    Теперь что касается регрессии. Основых метрики две - MSE и MAE. Из первой стоит извлекать корень, чтобы получать интерпретируемые человеком значения, а вторая менее агрессивна к выбросам (впрочем, выбросов тут уже нет, мы их все выкинули). Без дополнительной информации не очень понятно, какую выбирать, можно брать любую. А выбирать надо: ведь даже банальные модели \"предсказывай всегда среднее\" и \"предсказывай всегда медиану\" будут по-разному ранжироваться этими метриками.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs-jkCj-GH7G"
      },
      "source": [
        "**Вопрос третий**: а не взять ли нам какую-нибудь более экзотическую метрику? Например, MAPE (определение в учебнике в главе про оценку качества моделей). А как вам такое соображение: допустим, заказчик говорит, что пользователи будут расстраиваться, только если мы завысили средний чек - так давайте поправим MSE или MAE, обнуляя те слагаемые, для которых предсказанный таргет меньше истинного. Вот это хорошая метрика или нет?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "    Что касается MAPE, у нас нет тех проблем, с которой она борется. Вот если бы у нас были средние чеки от 500 до миллиона, мы бы столкнулись с ситуацией, что большие ошибки для больших чеков доминировали бы в сумме для MSE и MAE (500 вместо 1000 меркнет по сравнению с 500к вместо миллиона). Говоря поэтически, мы бы оптимизировали модель для миллионеров, забыв про простых трудяг. И было бы логично перейти от парадигмы \"ошибаемся на 500 рублей\" к парадигме \"ошибаемся на 50%\". Но у нас все таргеты примерно одного порядка, MAPE нам особо ни к чему.\n",
        "    \n",
        "    Вторая метрика коварна тем, что её можно \"накрутить\" безо всякой пользы для дела. А именно, модель, которая всегда предсказывает средний чек в миллион, была бы идеальна. Но все бы расстраивались и не ходили есть. Другое дело, что можно ввести разные веса для ошибок в большую и в меньшую сторону, но опять же - пока нет показаний к тому, что это нужно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCjV_SoAGH7G"
      },
      "source": [
        "## Применяем ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqkvcLSPGH7G"
      },
      "source": [
        "Теперь время разбить данные на обучающую и тестовую выборку. Делается это с помощью функции ``train_test_split`` из пакета ``sklearn``. При этом очень важно сделать две вещи:\n",
        "\n",
        "* Зафиксировать ``random_state=42`` (да, именно этот, а то ваши модели могут не зайти в Контест), чтобы всё, что мы делаем, было воспроизводимо (иначе от перезапуска к перезапуску числа могут меняться, и мы не будем понимать, из-за чего это происходит).\n",
        "* Сделать стратификацию по таргету. В противном случае у нас в трейне и тесте могут оказаться разные пропорции классов (обычно особенно страдают мало представленные классы), что неутешительно скажется на результате.\n",
        "\n",
        "**Обратите внимание**, что если вы побьёте выборку на train и test по-другому, ваши результаты могут не зайти в контест."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AF2IVpOjGH7H"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 21531 Test size: 10605\n"
          ]
        }
      ],
      "source": [
        "clean_data_train, clean_data_test = train_test_split(\n",
        "    clean_data, \n",
        "    stratify=clean_data['average_bill'], \n",
        "    test_size=0.33, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(clean_data_train), \"Test size:\", len(clean_data_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S161veFJGH7H"
      },
      "source": [
        "Теперь нам нужен **бейзлайн** - очень простая модель, с которой мы в дальнейшем будем сравниваться.\n",
        "\n",
        "Поскольку мы ещё не знаем никаких умных классов моделей, все модели мы будем писать руками. А именно, мы напишем две простых модели на основе ``sklearn.baseRegressorMixin`` и ``sklearn.base.ClassifierMixin`` (посмотрите примеры в документации sklearn и сделайте так же):\n",
        "\n",
        "* Модель для задачи регрессии, которая для всех заведений предсказывает одно число — среднее значение среднего чека;\n",
        "* Модель для задачи классификации, которая для всех заведений предсказывает один класс — самый частый класс (ироничным образом он в данном случае совпадает с медианой).\n",
        "\n",
        "**Важно!** Мы будем много раз повторять вам мантру о том, что **информация из тестовой выборки не должна протекать в процесс обучения**. Так вот, и среднее, и самый частый класс вы должны считать именно на обучающей выборке!\n",
        "\n",
        "**5 и 6. Напишите эти две модели и сдайте в Контест**. В процессе проверки модели будут и обучаться, и предсказывать.\n",
        "\n",
        "Заметим, что для этих моделей нам вообще не нужны какие-то \"фичи\"; мы работаем только с таргетом.\n",
        "\n",
        "У каждой модели есть (как минимум) два метода: `fit` (обучает модель по фичам `X` и таргету `y`) `predict` (предсказывает по фичам `X`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lLz_sxtUGH7H"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import mode\n",
        "\n",
        "from sklearn.base import RegressorMixin\n",
        "\n",
        "class MeanRegressor(RegressorMixin):\n",
        "    # Predicts the mean of y_train\n",
        "    def fit(self, X=None, y=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Training data features\n",
        "        y : array like, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        self.mean_ = np.mean(y)\n",
        "        return self  # возвращаем self, чтобы в дальнейшем можно было писать reg = MeanRegressor().fit(...)\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Data to predict\n",
        "        '''\n",
        "        \"\"\"\n",
        "        Предсказываем сохранённое среднее для любой выборки\n",
        "        \"\"\"\n",
        "        n_objects = X.shape[0] if X is not None else 1\n",
        "        return np.full(shape=(n_objects,), fill_value=self.mean_)\n",
        "\n",
        "from sklearn.base import ClassifierMixin\n",
        "\n",
        "class MostFrequentClassifier(ClassifierMixin):\n",
        "    # Predicts the rounded (just in case) median of y_train\n",
        "    def fit(self, X=None, y=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Training data features\n",
        "        y : array like, shape = (_samples,)\n",
        "        Training data targets\n",
        "        '''\n",
        "        \"\"\"\n",
        "        Запоминаем самый частотный класс из y на обучающей выборке\n",
        "        \"\"\"\n",
        "        # способ через np.unique:\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        self.most_freq_class_ = values[np.argmax(counts)]\n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        '''\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array like, shape = (n_samples, n_features)\n",
        "        Data to predict\n",
        "        '''\n",
        "        \"\"\"\n",
        "        Предсказываем сохранённый самый частотный класс для любой выборки\n",
        "        \"\"\"\n",
        "        n_objects = X.shape[0] if X is not None else 1\n",
        "        return np.full(shape=(n_objects,), fill_value=self.most_freq_class_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo2pNhVoGH7I"
      },
      "source": [
        "Обучим наши модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "arXlaGnTGH7I"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<__main__.MostFrequentClassifier at 0x7fcdf4532c50>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reg = MeanRegressor()\n",
        "reg.fit(y=clean_data_train['average_bill'])\n",
        "\n",
        "clf = MostFrequentClassifier()\n",
        "clf.fit(clean_data_train, clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Посмотрим, насколько хорошо справился регрессор:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 500.0: total=7368, correct=7368\n",
            "Class 1000.0: total=1809, correct=0\n",
            "Class 1500.0: total=890, correct=0\n",
            "Class 2000.0: total=391, correct=0\n",
            "Class 2500.0: total=147, correct=0\n"
          ]
        }
      ],
      "source": [
        "pred_vals_clf = clf.predict(clean_data_test)\n",
        "\n",
        "true_vals_clf = clean_data_test['average_bill'].values\n",
        "\n",
        "for c in np.unique(true_vals_clf):\n",
        "    mask_class = (true_vals_clf == c)\n",
        "    total_in_class = mask_class.sum()\n",
        "    correct_in_class = ((true_vals_clf == pred_vals_clf) & mask_class).sum()\n",
        "    print(f\"Class {c}: total={total_in_class}, correct={correct_in_class}\")\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJG8x0tmGH7I"
      },
      "source": [
        "Обучите модели и оцените их качество на тестовой выборке. В качестве метрик возьмём RMSE (``np.sqrt`` от ``sklearn.metrics.mean_squared_error``) и ``sklearn.metrics.balanced_accuracy_score``.\n",
        "\n",
        "Для регрессионной модели имеет смысл считать только RMSE (значения будут не кратны 500, точно мы угадывать не будем никогда), а вот для классификационной можно найти обе метрики. Сделайте это. Какая модель оказалась лучше по RMSE?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvZwp54sGH7J"
      },
      "source": [
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда</summary>\n",
        "    \n",
        "  Казалось бы, регрессор никогда не угадывает, но он в каком-то смысле лучше классификатора - справедливо ли это? Возможно. Несуществующий пользователь модели вряд ли будет задавать вопросы \"почему средний чек не кратен 500?\" Ну, выдали около 800 - ок, понятно.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-1-O9GyGH7J"
      },
      "source": [
        "## Усложнение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGWgxl0VGH7J"
      },
      "source": [
        "Бейзлайны будут нашей отправной точкой. Строя дальнейшие модели, мы будем спрашивать себя: получилось ли лучше бейзлайна? Если нет или если не особо, то в чём смысл усложнения?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9w3DkuuFGH7K"
      },
      "source": [
        "Начнём с использования фичи ``city``. Мы уже видели, что в разных городах и средние чеки разные. Легко проверить, что *медиана* средних чеков всё же одна и та же и в Москве, и в Санкт-Петербурге (ох уж этот вездесущий средний чек 500!), поэтому с классификатором мы ничего не сделаем. Но вот регрессор можно попробовать починить.\n",
        "\n",
        "**7. Напишите регрессор, для каждого заведения предсказывающий среднее значение в том же городе (на обучающей выборке, конечно) и сдайте его в Контест**. Вам может помочь то, что булевы `pandas` и `numpy` столбцы можно умножать на численные — в такой ситуации False работает, как ноль, а True как единица."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZULQVPe2GH7K"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import RegressorMixin\n",
        "\n",
        "class CityMeanRegressor(RegressorMixin):\n",
        "    def fit(self, X=None, y=None): \n",
        "        \"\"\"\n",
        "        Запоминаем средний чек для объектов из Москвы и для объектов из Питера.\n",
        "        \"\"\"\n",
        "        # Маски для строк из Москвы и Питера\n",
        "        mask_msk = (X['city'] == 'msk')\n",
        "        mask_spb = (X['city'] == 'spb')\n",
        "        \n",
        "        self.mean_msk_ = y[mask_msk].mean()  # среднее y по Москве\n",
        "        self.mean_spb_ = y[mask_spb].mean()  # среднее y по Питеру\n",
        "        \n",
        "        \n",
        "        return self\n",
        "\n",
        "    def predict(self, X=None):\n",
        "        \"\"\"\n",
        "        Для объектов из Москвы предсказываем self.mean_msk_,\n",
        "        для объектов из Питера — self.mean_spb_.\n",
        "        \"\"\"\n",
        "        # Пошаговый способ (списки):\n",
        "        predictions = []\n",
        "        for city_val in X['city']:\n",
        "            if city_val == 'msk':\n",
        "                predictions.append(self.mean_msk_)\n",
        "            elif city_val == 'spb':\n",
        "                predictions.append(self.mean_spb_)\n",
        "        return np.array(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EeFGk24GH7K"
      },
      "source": [
        "Обучите регрессор и сравните его по метрике RMSE с бейзлайнами. Получилось ли улучшить метрику?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[677.71044658 792.61119082 792.61119082 ... 792.61119082 792.61119082\n",
            " 677.71044658]\n"
          ]
        }
      ],
      "source": [
        "city_reg = CityMeanRegressor()\n",
        "city_reg.fit(clean_data_train, clean_data_train['average_bill'])\n",
        "\n",
        "y_pred_city_reg = city_reg.predict(clean_data_test)\n",
        "print(y_pred_city_reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jROycei1GH7L"
      },
      "source": [
        "Лучше стало, но, правда, не очень сильно. В этот момент очень важно не просто радовать руководителя приростом в третьем знаке, но и думать о том, что происходит.\n",
        "\n",
        "Средний средний чек по Москве равен 793, в Санкт-Петербурге - 676, а в целом - 752 рубля. MSE, увы, не поможет вам ответить на вопрос, стало ли лучше пользователю, если вы ему вместо 752 рублей назвали 793. Здесь вскрывается весьма существенный порок MSE в этой задаче. Дело в том, что наш изначальный таргет делит заведения на некоторые \"ценовые категории\", и различие в средних чеках 500 и 1000 в самом деле существенно. Наверное, мы хотели бы как раз правильно предсказывать ценовые категории. Но MSE не очень помогает нам об этом судить. Дальше мы ещё подумаем, как это исправить.\n",
        "\n",
        "В любом случае, несмотря на улучшение метрики, мы пока не можем судить, стало ли по жизни лучше от усложнения модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CityMeanRegressor RMSE = 445.1063281403263\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "rmse_city_reg = np.sqrt(mean_squared_error(clean_data_test['average_bill'], y_pred_city_reg))\n",
        "print(\"CityMeanRegressor RMSE =\", rmse_city_reg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEQ9eOoWGH7L"
      },
      "source": [
        "Поручинившись немного, возьмём на вооружение другую идею. Давайте использовать типы заведений!\n",
        "\n",
        "Но с типами есть некоторая проблема: в столбце ``rubrics_id`` не всегда один идентификатор, часто их несколько, и всего комбинаций довольно много. Чтобы не возиться с малочисленными типами, давайте сольём их в один безликий ``other``.\n",
        "\n",
        "Итак, добавьте в обучающие и тестовые данные столбец ``modified_rubrics``, в котором будет то же, что и в ``rubrics_id``, если соответствующая комбинация рубрик содержит хотя бы 100 заведений из обучающей (!) выборки, и строка ``other`` в противном случае.\n",
        "\n",
        "Здесь вам поможет контейнер ``Counter`` из библиотеки ``collections``."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "uTVW5KkwGH7L"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def build_modified_rubrics(train_df, test_df, threshold=100):\n",
        "    \"\"\"\n",
        "    Создаёт столбец 'modified_rubrics' в обоих датасетах,\n",
        "    где все нечастые комбинации заменены на 'other'.\n",
        "    \"\"\"\n",
        "    rubr_counter = Counter(train_df['rubrics_id']) #Считаем частоты рубрик в train\n",
        "    \n",
        "    def to_modified_rubr(rubr_str):\n",
        "        count_ = rubr_counter[rubr_str]\n",
        "        if count_ >= threshold:\n",
        "            return rubr_str\n",
        "        else:\n",
        "            return 'other'\n",
        "    \n",
        "    train_df['modified_rubrics'] = train_df['rubrics_id'].apply(to_modified_rubr)\n",
        "    \n",
        "    def to_modified_rubr_test(rubr_str):\n",
        "        if rubr_str not in rubr_counter:  # здесь мы смотрим только на rubr_counter (из train!),\n",
        "            return 'other'\n",
        "        elif rubr_counter[rubr_str] >= threshold:\n",
        "            return rubr_str\n",
        "        else:\n",
        "            return 'other'\n",
        "    \n",
        "    test_df['modified_rubrics'] = test_df['rubrics_id'].apply(to_modified_rubr_test)\n",
        "    \n",
        "    return train_df, test_df\n",
        "\n",
        "\n",
        "clean_data_train, clean_data_test = build_modified_rubrics(clean_data_train, clean_data_test, threshold=100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZXhpBjnGH7L"
      },
      "source": [
        "Теперь настало время написать могучий классификатор, который по заведению предсказывает медиану средних чеков среди тех в обучающей выборке, у которых с ним одинаковые `modified_rubrics` и город (вы спросите, почему медиану, а не самый частый -- спишем это на вдохновение; самый частый тоже можно брать - но медиана работает лучше).\n",
        "\n",
        "**8. Напишите классификатор и сдайте в Контест**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eTfcwh5dGH7M"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import ClassifierMixin\n",
        "import numpy as np\n",
        "\n",
        "class RubricCityClassifier(ClassifierMixin):\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Запоминаем, для каждой (city, modified_rubrics) - медиану y,\n",
        "        а также глобальную медиану на случай отсутствия комбинации.\n",
        "        \"\"\"\n",
        "        self.dict_ = {}\n",
        "        \n",
        "        # Склеим X,y в одну таблицу для удобства\n",
        "        df = X.copy()\n",
        "        df['average_bill'] = y.values\n",
        "        \n",
        "        # Глобальная медиана (по трейну)\n",
        "        self.global_median_ = np.median(y)\n",
        "        \n",
        "        # Группировка по (city, modified_rubrics)\n",
        "        grouped = df.groupby(['city', 'modified_rubrics'])['average_bill']\n",
        "        \n",
        "        # Считаем медиану в каждой группе\n",
        "        # Это будет pd.Series с MultiIndex [(city, rubrics), ...] и значением медианы\n",
        "        med_series = grouped.median()\n",
        "        \n",
        "        # Превращаем в обычный словарь {(city, rubrics): median_value, ...}\n",
        "        self.dict_ = med_series.to_dict()\n",
        "        \n",
        "        # Подготовим множество возможных дискретных таргетов, чтобы потом округлять\n",
        "        self.all_bills_ = np.sort(df['average_bill'].unique())\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def _round_to_known_bills(self, val):\n",
        "        \"\"\"\n",
        "        Округляет число val до ближайшего из self.all_bills_ (например, [500,1000,1500,...])\n",
        "        \"\"\"\n",
        "        # Поиск индекса в отсортированном массиве self.all_bills_\n",
        "        idx = np.searchsorted(self.all_bills_, val)\n",
        "        # idx - это позиция, куда можно вставить val, чтобы сохранить порядок\n",
        "        # нужно сравнить self.all_bills_[idx-1] и self.all_bills_[idx], где idx может быть 0 или len(array)\n",
        "        if idx == 0:\n",
        "            return self.all_bills_[0]\n",
        "        elif idx == len(self.all_bills_):\n",
        "            return self.all_bills_[-1]\n",
        "        else:\n",
        "            # ближайший из двух соседей\n",
        "            left_ = self.all_bills_[idx-1]\n",
        "            right_ = self.all_bills_[idx]\n",
        "            if abs(left_ - val) <= abs(right_ - val):\n",
        "                return left_\n",
        "            else:\n",
        "                return right_\n",
        "    \n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Для объекта из (city, modified_rubrics) возвращаем округлённую медиану,\n",
        "        если связка есть в self.dict_. Иначе берём глобальную медиану.\n",
        "        \"\"\"\n",
        "        preds = []\n",
        "        for city_val, rubr_val in zip(X['city'], X['modified_rubrics']):\n",
        "            key = (city_val, rubr_val)\n",
        "            if key in self.dict_:\n",
        "                raw_median = self.dict_[key]\n",
        "            else:\n",
        "                raw_median = self.global_median_\n",
        "            # округляем к ближайшему известному таргету\n",
        "            final_pred = self._round_to_known_bills(raw_median)\n",
        "            preds.append(final_pred)\n",
        "        return np.array(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbgjbwgkGH7M"
      },
      "source": [
        "Сравните обученный классификатор по метрикам RMSE и balanced_accuracy_score с нашими бейзлайнами. Получилось ли улучшить?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rubric+City classifier balanced_accuracy = 0.30552511833185647\n",
            "Rubric+City classifier RMSE = 393.96675836287915\n"
          ]
        }
      ],
      "source": [
        "rubr_city_clf = RubricCityClassifier()\n",
        "rubr_city_clf.fit(clean_data_train, clean_data_train['average_bill'])\n",
        "\n",
        "y_pred_rubr_city = rubr_city_clf.predict(clean_data_test)\n",
        "\n",
        "from sklearn.metrics import balanced_accuracy_score, mean_squared_error\n",
        "\n",
        "bal_acc = balanced_accuracy_score(clean_data_test['average_bill'], y_pred_rubr_city)\n",
        "rmse_rc = np.sqrt(mean_squared_error(clean_data_test['average_bill'], y_pred_rubr_city))\n",
        "\n",
        "print(\"Rubric+City classifier balanced_accuracy =\", bal_acc)\n",
        "print(\"Rubric+City classifier RMSE =\", rmse_rc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMjsnCnQGH7M"
      },
      "source": [
        "Обратите внимание что рост accuracy по сравнению с бейзлайном при этом на порядок меньше:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2cF0I-CGH7M"
      },
      "source": [
        "accuracy_score\n",
        "\n",
        "Predict most frequent:  0.6947666195190948\n",
        "\n",
        "Predict by rubric and city:  0.7095709570957096"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Часто обнаружится, что более редкие классы модель угадывает не очень хорошо."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 500.0: total=7368, correct=6608\n",
            "Class 1000.0: total=1809, correct=700\n",
            "Class 1500.0: total=890, correct=217\n",
            "Class 2000.0: total=391, correct=0\n",
            "Class 2500.0: total=147, correct=0\n"
          ]
        }
      ],
      "source": [
        "true_vals = clean_data_test['average_bill'].values\n",
        "pred_vals = y_pred_rubr_city\n",
        "\n",
        "for c in np.unique(true_vals):\n",
        "    mask_class = (true_vals == c)\n",
        "    total_in_class = mask_class.sum()\n",
        "    correct_in_class = ((true_vals == pred_vals) & mask_class).sum()\n",
        "    print(f\"Class {c}: total={total_in_class}, correct={correct_in_class}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylrAIjCcGH7N"
      },
      "source": [
        "Для диагностики напечатайте для каждого класса тестовой выборки, сколько в нём объектов и скольким из них наш классификатор приписал правильный класс. Что вы видите?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "    \n",
        "  Вы, вероятно, видите то, что мы стали однозначно лучше по сравнению с бейзлайном детектировать средний чек 1000 и 1500 (хотя всё равно не очень хорошо + ценой ухудшения качества на среднем чеке 500), а вот чеки 2000 и 2500 нам ну никак не даются.\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ScOy7ZvGH7N"
      },
      "source": [
        "**Кстати**. А вы понимаете, почему приведённый выше пайплайн классификации был не очень удачным с точки зрения архитектуры? Почему его было бы правильнее воплотить по-другому?\n",
        "\n",
        "&nbsp;\n",
        "\n",
        "<details>\n",
        "  <summary>Когда будете готовы, кликните сюда, чтобы посмотреть ответ</summary>\n",
        "Собственно говоря, и не было никакого пайплайна. К счастью, у нас была одна обучающая выборка, мы на ней посчитали список рубрик для modified_rubrics и радовались жизни. Но если бы нам надо было переобучать всё на новых данных, пришлось бы помнить, что их надо везде пересчитать (ведь у нас могли появиться новые рубрики с хотя бы 100 представителями). А уж никакую кросс-валидацию (кто знает - тот поймёт) с нашим подходом к делу и вовсе бы не получилось сделать без боли.\n",
        "    \n",
        "Поэтому в следующей лабораторной вы научитесь делать честные пайплайны, в которых преобразование данных, генерация фичей и обучение классификатора будут объединены в один понятный процесс, происходящий на этапе fit.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ujl3tbbGH7N"
      },
      "source": [
        "## Слишком простые и слишком сложные модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF7McCHsGH7N"
      },
      "source": [
        "Бейзлайны у нас слишком просты и потому не очень полезны в жизни. Но если сложность модели растёт бесконтрольно, то тоже получается плохо.\n",
        "\n",
        "Давайте рассмотрим конкретный пример. Создадим классификатор, использующий одновременно `rubrics_id` и `features_id`.\n",
        "\n",
        "Сделайте следующее:\n",
        "\n",
        "- для каждого объекта обучающей выборки сконкатенируйте строку `rubrics_id` с разделителем (например, буквой 'q') и содержимым `features_id`. Полученный столбец озаглавьте `modified_features`. Это не самый клёвый способ заиспользовать все фичи, но сейчас пока сойдёт. Причём на сей раз не будем выкидывать мало представленные значения (вся информация важна, не так ли?).\n",
        "- при этом для тестовой выборке заменяйте на строку `other` все конкатенации, которые не встретились в обучающей выборке.\n",
        "\n",
        "То есть элементы в этом столбце будут иметь вид `other` или `30776 30774 q 3502045032 11741 3502045016 1046...`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Формируем \"modified_features\" в train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Обучаемся"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8tNBPzVGH7O"
      },
      "source": [
        "Теперь обучите классификатор, который для заведения предсказывает медиану среднего чека по всем объектам тестовой выборки с таким же, как у него, значением `modified_features`, а если такого в обучающей выборке нет, то глобальную медиану среднего чека по всей обучающей выборке.\n",
        "\n",
        "**9. Загрузите в Контест предсказания этого классификатора на тестовой выборке**\n",
        "\n",
        "Мы ждём файла **.csv**, у которого в каждой строке будет только одно число - предсказание классификатора.\n",
        "\n",
        "Возможно, вам будет полезна библиотека ``tqdm``, позволяющая отслеживать в реальном времени, сколько времени уже крутится цикл и сколько итераций ещё осталось. Впрочем, если вы всё написали нормально, то должно работать не очень долго."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Предсказываем на тесте и выгружаем в .csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Файл 'task9_predictions.csv' для Контеста сохранён.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def make_rubfeat_str(rubrics_id, features_id):\n",
        "    return rubrics_id + 'q' + features_id\n",
        "\n",
        "train_medians_dict = {}\n",
        "\n",
        "tmp_map = {}\n",
        "\n",
        "for i, row in clean_data_train.iterrows():\n",
        "    combo_str = make_rubfeat_str(row['rubrics_id'], row['features_id'])\n",
        "    if combo_str not in tmp_map:\n",
        "        tmp_map[combo_str] = []\n",
        "    tmp_map[combo_str].append(row['average_bill'])\n",
        "\n",
        "for key, bills in tmp_map.items():\n",
        "    train_medians_dict[key] = np.median(bills)\n",
        "\n",
        "global_median = np.median(clean_data_train['average_bill']) # глобальную медиана, если ничего не найдётся\n",
        "\n",
        "predictions_task9 = [] # для теста\n",
        "\n",
        "for i, row in clean_data_test.iterrows():\n",
        "    combo_str = make_rubfeat_str(row['rubrics_id'], row['features_id'])\n",
        "    if combo_str in train_medians_dict:\n",
        "        pred_val = train_medians_dict[combo_str]\n",
        "    else:\n",
        "        if \"other\" in train_medians_dict:\n",
        "            pred_val = train_medians_dict[\"other\"]\n",
        "        else:\n",
        "            pred_val = global_median\n",
        "    predictions_task9.append((row['org_id'], pred_val))\n",
        "\n",
        "with open('task9_predictions.csv', 'w', encoding='utf-8') as f:\n",
        "    for org_id_val, pred_val in predictions_task9:\n",
        "        f.write(f\"{org_id_val},{int(pred_val)}\\n\")\n",
        "\n",
        "print(\"Файл сохранён.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XrswPW4GH7O"
      },
      "source": [
        "Модель, очевидно, очень сложная. Число параметров (различных категорий) в ней сопоставимо с числом объектов в обучающей выборке. А получилось ли хорошо?\n",
        "\n",
        "Давайте посчитаем RMSE и balanced_accuracy_score на обучающей и на тестовой выборках.\n",
        "\n",
        "**10. Введите их в Контест**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGDTpxFgGH7O"
      },
      "source": [
        "Налицо переобучение: на трейне метрики отличные, на тесте - вообще никакие\n",
        "\n",
        "В общем, не гонитесь за чрезмерной сложностью модели.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Простая функция, которая формирует для df_source предсказания на основе словаря train_medians (rubrics+features -> медиана).\n",
        "Если нет ключа, пытается 'other', иначе глобальная медиана:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "def predict_median_rubfeat(df_source, train_medians, global_med):\n",
        "    preds = []\n",
        "    for i, row in df_source.iterrows():\n",
        "        key = make_rubfeat_str(row['rubrics_id'], row['features_id'])\n",
        "        if key in train_medians:\n",
        "            preds.append(train_medians[key])\n",
        "        else:\n",
        "            if \"other\" in train_medians:\n",
        "                preds.append(train_medians[\"other\"])\n",
        "            else:\n",
        "                preds.append(global_med)\n",
        "    return np.array(preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Повторим обучение на train:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tmp_map_10 = {}\n",
        "for i, row in clean_data_train.iterrows():\n",
        "    combo_str = make_rubfeat_str(row['rubrics_id'], row['features_id'])\n",
        "    if combo_str not in tmp_map_10:\n",
        "        tmp_map_10[combo_str] = []\n",
        "    tmp_map_10[combo_str].append(row['average_bill'])\n",
        "\n",
        "train_medians_dict_10 = {}\n",
        "for key, bills in tmp_map_10.items():\n",
        "    train_medians_dict_10[key] = np.median(bills)\n",
        "\n",
        "global_median_10 = np.median(clean_data_train['average_bill'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Предсказываем на train и test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_preds_10 = predict_median_rubfeat(clean_data_train, train_medians_dict_10, global_median_10)\n",
        "test_preds_10  = predict_median_rubfeat(clean_data_test,  train_medians_dict_10, global_median_10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Считаем RMSE и balanced_acc:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32.42 0.99 513.99 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ekaterina/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
            "/home/ekaterina/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2524: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
          ]
        }
      ],
      "source": [
        "rmse_train_10 = sqrt(mean_squared_error(clean_data_train['average_bill'], train_preds_10))\n",
        "balacc_train_10 = balanced_accuracy_score(clean_data_train['average_bill'], train_preds_10)\n",
        "\n",
        "rmse_test_10 = sqrt(mean_squared_error(clean_data_test['average_bill'], test_preds_10))\n",
        "balacc_test_10 = balanced_accuracy_score(clean_data_test['average_bill'], test_preds_10)\n",
        "\n",
        "rmse_train_10_rounded = round(rmse_train_10, 2)\n",
        "balacc_train_10_rounded = round(balacc_train_10, 2)\n",
        "rmse_test_10_rounded = round(rmse_test_10, 2)\n",
        "balacc_test_10_rounded = round(balacc_test_10, 2)\n",
        "\n",
        "print(rmse_train_10_rounded, \n",
        "      balacc_train_10_rounded, \n",
        "      rmse_test_10_rounded, \n",
        "      balacc_test_10_rounded)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTU2yubYGH7O"
      },
      "source": [
        "## ML без данных что компутер без электричества"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBVOCVf2GH7P"
      },
      "source": [
        "Возможно, вы смотрите на полученные выше результаты и думаете: вот если бы мы не какие-то убогие медианы предсказывали, а гоняли бы нейросети, то тут-то бы всё и получилось!\n",
        "\n",
        "Но, увы, совсем даже не всегда от счастья нас отделяет выбор хорошей модели (и стратегии обучения). Если данные не очень, то даже самая крутая модель не сработает. В этой ситуации нужно либо добывать новые фичи каким-то образом, либо собирать новые данные (увеличивать датасет), либо просто бросать задачу.\n",
        "\n",
        "Давайте посмотрим, что выжмет из наших данных одна из самых мощных моделей для табличных данных - градиентный бустинг на решающих деревьях в исполнении [CatBoost](https://catboost.ai/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0L4UmzSGH7P"
      },
      "source": [
        "Но прежде, чем сделать fit, нам надо облагородить данные. Несмотря на то, что CatBoost отлично работает с категориальными фичами, мешок признаков из `rubrics_id` или `features_id` может ему оказаться не по зубам. Поэтому мы соберём датасет в пристойную матрицу, создав для каждого типа рубрик и фичей отдельный столбец и записав там единицы для тех объектов, у которых эта рубрика или фича имеет место.\n",
        "\n",
        "В матрице почти все элементы будут нулями. Такие матрицы считаются **разреженными** и их можно хранить гораздо эффективней, чем просто таблицей. Этим и займёмся)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJKuMtNbGH7P"
      },
      "source": [
        "Есть несколько форматов хранения разреженных матриц (многие из них реализованы в [пакете sparse библиотеки scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)), и каждый пригоден для чего-то своего.\n",
        "\n",
        "Создавать разреженную матрицу лучше в [формате COO](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.coo_array.html#scipy.sparse.coo_array). Он предполагает, что разреженная матрица задаётся в виде трёх списков: `row`, `col`, `data`, причём каждая тройка `(row[i], col[i], data[i])` кодирует элемент со значением `data[i]`, стоящий на позиции `(row[i], col[i])`. Считается, что на позициях `(row, col)`, которые ни разу не встретились, стоят нули.\n",
        "\n",
        "Нетрудно видеть, что заполнять такую матрицу - одно удовольствие, и особенно этому помогает тот факт, что **пара `(row, col)` может встретиться несколько раз** (тогда в итоговой матрице на соответствующей позиции стоит сумма соответствующих `data[i]`). Но, с другой стороны, почти ничего другого с такой матрицей не сделаешь: произвольного доступа к элементам она не предоставляет, умножить её тоже особо ничего не умножишь. Поэтому для дальнейшего использования созданную таким образом матрицу преобразуют в один из более удобных форматов, например, [CSR (compressed sparse row)](https://scipy-lectures.org/advanced/scipy_sparse/csr_matrix.html). Он, к примеру, хорошо подходит для умножения на вектор (потому что матрица хранится по строкам). Не будем разбирать его подробно, но можете почитать по ссылке, если интересно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hd_Sob3GH7P"
      },
      "source": [
        "Вам нужно будет превратить обучающие и тестовые данные в разреженные матрицы `sparse_data_train` и `sparse_data_test` соответственно, таким образом, что:\n",
        "\n",
        "- столбец `city` превратится в столбец из единиц и нулей (например, 1 - Москва, 0 - Питер);\n",
        "- столбец `rating` перекочует в разреженные матрицы без изменений;\n",
        "- каждый типы рубрик и каждая фича превратятся в отдельный 0-1-принак;\n",
        "\n",
        "В тестовой выборке будут фичи, которых в обучающей выборке не было. С ними можно по-разному работать, но давайте создадим дополнительную фантомную фичу `feature_other`, в которой будет то, сколько неизвестных по обучающей выборке фичей есть у данного объекта."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "7-UAatGJGH7P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Библиотеки успешно установлены и импортированы!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from scipy.stats import mode\n",
        "from math import sqrt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, balanced_accuracy_score\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "\n",
        "print(\"Библиотеки успешно установлены и импортированы!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def df_to_sparse(df):\n",
        "    \"\"\"\n",
        "    Преобразует DataFrame (с колонками city, rating, rubrics_id, features_id) в CSR-матрицу.\n",
        "    \"\"\"\n",
        "    row_inds = []\n",
        "    col_inds = []\n",
        "    data_vals = []\n",
        "    \n",
        "    for row_i, row in enumerate(df.itertuples(index=False)):\n",
        "        \n",
        "        city_val = 1.0 if row.city == 'msk' else 0.0\n",
        "        row_inds.append(row_i)\n",
        "        col_inds.append(0)\n",
        "        data_vals.append(city_val)\n",
        "        \n",
        "        rating_val = row.rating if not np.isnan(row.rating) else 0.0 # rating: если NaN, ставим 0 \n",
        "        row_inds.append(row_i)\n",
        "        col_inds.append(1)\n",
        "        data_vals.append(rating_val)\n",
        "        \n",
        "        rubs = row.rubrics_id.split()\n",
        "        for r in rubs:\n",
        "            if r in rubrics_index:\n",
        "                j = rubrics_index[r] + 2  # +2, тк 0 и 1 заняты city/rating\n",
        "                row_inds.append(row_i)\n",
        "                col_inds.append(j)\n",
        "                data_vals.append(1.0)\n",
        "        \n",
        "        feats = row.features_id.split()\n",
        "        for f in feats:\n",
        "            if f in features_index:\n",
        "                j = features_index[f] + 2 + len(rubrics_index) # для фич инлекс начинается после всех рубрик\n",
        "                row_inds.append(row_i)\n",
        "                col_inds.append(j)\n",
        "                data_vals.append(1.0)\n",
        "            else: \n",
        "                j = 2 + len(rubrics_index) + feature_other_idx # для фич, которых не было в трейне\n",
        "                row_inds.append(row_i)\n",
        "                col_inds.append(j)\n",
        "                data_vals.append(1.0)\n",
        "    \n",
        "    n_rows = len(df)\n",
        "    n_cols = 2 + len(rubrics_index) + len(features_index) + 1  # +1 для feature_other\n",
        "    coo_mat = sparse.coo_matrix((data_vals, (row_inds, col_inds)), shape=(n_rows, n_cols))\n",
        "    \n",
        "    csr_mat = coo_mat.tocsr()\n",
        "    return csr_mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Собираем sparse-матрицы:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'rubrics_index' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sparse_data_train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_to_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_data_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sparse_data_test  \u001b[38;5;241m=\u001b[39m df_to_sparse(clean_data_test)\n",
            "Cell \u001b[0;32mIn[34], line 23\u001b[0m, in \u001b[0;36mdf_to_sparse\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m rubs \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mrubrics_id\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rubs:\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrubrics_index\u001b[49m:\n\u001b[1;32m     24\u001b[0m         j \u001b[38;5;241m=\u001b[39m rubrics_index[r] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# +2, тк 0 и 1 заняты city/rating\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         row_inds\u001b[38;5;241m.\u001b[39mappend(row_i)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rubrics_index' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "sparse_data_train = df_to_sparse(clean_data_train)\n",
        "sparse_data_test  = df_to_sparse(clean_data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFfj-1E4GH7Q"
      },
      "source": [
        "Данные готовы, и теперь можно запустить катбуст"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "m2lP5NouGH7Q"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoost успешно установлен и импортирован!\n"
          ]
        }
      ],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "print(\"CatBoost успешно установлен и импортирован!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "jpW6uR0oGH7Q"
      },
      "outputs": [],
      "source": [
        "clf_cat = CatBoostClassifier(verbose=False, random_state=42)\n",
        "clf_cat.fit(sparse_data_train, clean_data_train['average_bill'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBOpZY9BGH7Q"
      },
      "source": [
        "**11. Пришлите в Контест balanced_accuracy_score на тестовой выборке, округлённый до двух знаков после запятой**. Стало ли сильно лучше от того, что мы воспользовались таким крутым классификатором?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Предсказываем:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CatBoostClassifier balanced_accuracy_score на тесте: 0.36\n"
          ]
        }
      ],
      "source": [
        "pred_cat_test = clf_cat.predict(sparse_data_test)\n",
        "balacc_cat = balanced_accuracy_score(clean_data_test['average_bill'], pred_cat_test)\n",
        "balacc_cat_rounded = round(balacc_cat, 2)\n",
        "\n",
        "print(\"CatBoostClassifier balanced_accuracy_score на тесте:\", balacc_cat_rounded)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
